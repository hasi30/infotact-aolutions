# -*- coding: utf-8 -*-
"""intelligent task management .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CW2qbbuYGls3udpS8uQh9ZUYpkU-1zp-

TASK 1

data collection

explorotary data analysis

basic nlp operations and pre processing
"""

# === EDA and NLP Preprocessing for Task Management Data ===

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import classification_report

nltk.download('stopwords')
nltk.download('wordnet')

# === Load Data ===
df = pd.read_csv("/content/Combined_Task_Management.csv")  # Replace with your dataset file

# === Basic EDA ===
print("üìä Dataset Info:")
print(df.info())
print("\nüßπ Missing Values:")
print(df.isnull().sum())

print("\nüîç Category Distribution:")
if 'Category' in df.columns:
    print(df['Category'].value_counts())

# === Visualizations ===
if 'Category' in df.columns:
    plt.figure(figsize=(10, 6))
    sns.countplot(data=df, x='Category', order=df['Category'].value_counts().index)
    plt.title("Task Category Distribution")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# === NLP Preprocessing ===
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()
df.fillna("Unknown", inplace=True)

def clean_text(text):
    text = str(text).lower()  # Lowercase
    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove punctuation
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords
    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatize
    return " ".join(tokens)

if 'Task Description' in df.columns:
    df['Cleaned_Description'] = df['Task Description'].apply(clean_text)
    print("\n‚úÖ Sample cleaned task descriptions:")
    print(df[['Task Description', 'Cleaned_Description']].head())



# === Save Preprocessed Data ===
df.to_csv("preprocessed_task_data.csv", index=False)
print("\n‚úÖ Preprocessed data saved to 'preprocessed_task_data.csv'")

# === Load and Preprocess Data ===
df = pd.read_csv("Combined_Task_Management.csv")  # Combined dataset

# Fill missing values
df.fillna("Unknown", inplace=True)

# Encode target variables
le_category = LabelEncoder()
df['Category_encoded'] = le_category.fit_transform(df['Category'])

le_skill = LabelEncoder()
df['Skill_encoded'] = le_skill.fit_transform(df['Skill'])

print(df.isnull().sum())

print(df.columns.tolist())

le_owner = LabelEncoder()
df['TaskOwner_encoded'] = le_owner.fit_transform(df['Task Owner'])  # <-- Use exact name

print("\nTraining task classification model...")
X_desc = df['Task Description']
y_cat = df['Category_encoded']

vectorizer = TfidfVectorizer(max_features=1000)
X_vec = vectorizer.fit_transform(X_desc)

X_train, X_test, y_train, y_test = train_test_split(X_vec, y_cat, test_size=0.2, random_state=42)

clf = LogisticRegression(max_iter=200)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print("\nClassification Report (Category):")
print(classification_report(y_test, y_pred, target_names=le_category.classes_))

print("\nTraining task prioritization model...")
# Convert dates to duration
try:
    df['EntryDate'] = pd.to_datetime(df['EntryDate'])
    df['COmpleteDate'] = pd.to_datetime(df['COmpleteDate'])
    df['Duration'] = (df['COmpleteDate'] - df['EntryDate']).dt.days
except Exception:
    df['Duration'] = np.random.randint(1, 30, size=len(df))

priority_features = ['Duration', 'ReccuringRevenue', 'NRR']
priority_features = [feat for feat in priority_features if feat in df.columns]

X_priority = df[priority_features]
y_priority = df['NRR'] if 'NRR' in df.columns else df['ReccuringRevenue']

X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_priority, y_priority, test_size=0.2, random_state=42)

regressor = RandomForestRegressor(n_estimators=100, random_state=42)
regressor.fit(X_train_p, y_train_p)
print("\nTask prioritization model trained.")

print("\nTraining task assignment model...")
assignment_features = X_vec.toarray()  # From TF-IDF task descriptions
X_assignment = np.concatenate([assignment_features, df[['Skill_encoded', 'Category_encoded']].values], axis=1)
y_assignment = df['TaskOwner_encoded']

X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X_assignment, y_assignment, test_size=0.2, random_state=42)

assigner = LogisticRegression(max_iter=200)
assigner.fit(X_train_a, y_train_a)
print("\nTask assignment model trained.")

# === Prediction Example ===
def predict_new_task(task_text):
    task_vec = vectorizer.transform([task_text])
    task_array = task_vec.toarray()

    cat_pred = clf.predict(task_vec)[0]
    # If "Unknown" was not in the original Skill column, handle it during prediction:
    try:
        skill_pred = le_skill.transform(["Unknown"])[0]
    except ValueError:
        # Assign a default value (e.g., -1) for unknown skills
        skill_pred = -1

    X_assign = np.concatenate([task_array, [[skill_pred, cat_pred]]], axis=1)
    owner_pred = assigner.predict(X_assign)[0]

    print("\n--- New Task Prediction ---")
    print("Task Description:", task_text)
    print("Predicted Category:", le_category.inverse_transform([cat_pred])[0])
    print("Assigned To:", le_owner.inverse_transform([owner_pred])[0])

predict_new_task("third party services")